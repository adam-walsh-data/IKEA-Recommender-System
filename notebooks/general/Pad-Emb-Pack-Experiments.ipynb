{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding, embedding and packing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>len_state</th>\n",
       "      <th>action</th>\n",
       "      <th>is_buy</th>\n",
       "      <th>next_state</th>\n",
       "      <th>len_next_states</th>\n",
       "      <th>is_done</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[70852, 70852, 70852, 70852, 70852, 70852, 708...</td>\n",
       "      <td>1</td>\n",
       "      <td>49432</td>\n",
       "      <td>0</td>\n",
       "      <td>[49432, 70852, 70852, 70852, 70852, 70852, 708...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[49432, 70852, 70852, 70852, 70852, 70852, 708...</td>\n",
       "      <td>1</td>\n",
       "      <td>49432</td>\n",
       "      <td>0</td>\n",
       "      <td>[49432, 49432, 70852, 70852, 70852, 70852, 708...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[49432, 49432, 70852, 70852, 70852, 70852, 708...</td>\n",
       "      <td>2</td>\n",
       "      <td>39563</td>\n",
       "      <td>0</td>\n",
       "      <td>[49432, 49432, 39563, 70852, 70852, 70852, 708...</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[49432, 49432, 39563, 70852, 70852, 70852, 708...</td>\n",
       "      <td>3</td>\n",
       "      <td>32776</td>\n",
       "      <td>0</td>\n",
       "      <td>[49432, 49432, 39563, 32776, 70852, 70852, 708...</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[49432, 49432, 39563, 32776, 70852, 70852, 708...</td>\n",
       "      <td>4</td>\n",
       "      <td>52161</td>\n",
       "      <td>0</td>\n",
       "      <td>[49432, 49432, 39563, 32776, 52161, 70852, 708...</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[49432, 49432, 39563, 32776, 52161, 70852, 708...</td>\n",
       "      <td>5</td>\n",
       "      <td>52161</td>\n",
       "      <td>0</td>\n",
       "      <td>[49432, 49432, 39563, 32776, 52161, 52161, 708...</td>\n",
       "      <td>6</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[49432, 49432, 39563, 32776, 52161, 52161, 708...</td>\n",
       "      <td>6</td>\n",
       "      <td>32776</td>\n",
       "      <td>0</td>\n",
       "      <td>[49432, 49432, 39563, 32776, 52161, 52161, 327...</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[49432, 49432, 39563, 32776, 52161, 52161, 327...</td>\n",
       "      <td>7</td>\n",
       "      <td>49432</td>\n",
       "      <td>0</td>\n",
       "      <td>[49432, 49432, 39563, 32776, 52161, 52161, 327...</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[70852, 70852, 70852, 70852, 70852, 70852, 708...</td>\n",
       "      <td>1</td>\n",
       "      <td>9750</td>\n",
       "      <td>1</td>\n",
       "      <td>[9750, 70852, 70852, 70852, 70852, 70852, 7085...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[9750, 70852, 70852, 70852, 70852, 70852, 7085...</td>\n",
       "      <td>1</td>\n",
       "      <td>38594</td>\n",
       "      <td>0</td>\n",
       "      <td>[9750, 38594, 70852, 70852, 70852, 70852, 7085...</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               state  len_state  action  \\\n",
       "0  [70852, 70852, 70852, 70852, 70852, 70852, 708...          1   49432   \n",
       "1  [49432, 70852, 70852, 70852, 70852, 70852, 708...          1   49432   \n",
       "2  [49432, 49432, 70852, 70852, 70852, 70852, 708...          2   39563   \n",
       "3  [49432, 49432, 39563, 70852, 70852, 70852, 708...          3   32776   \n",
       "4  [49432, 49432, 39563, 32776, 70852, 70852, 708...          4   52161   \n",
       "5  [49432, 49432, 39563, 32776, 52161, 70852, 708...          5   52161   \n",
       "6  [49432, 49432, 39563, 32776, 52161, 52161, 708...          6   32776   \n",
       "7  [49432, 49432, 39563, 32776, 52161, 52161, 327...          7   49432   \n",
       "8  [70852, 70852, 70852, 70852, 70852, 70852, 708...          1    9750   \n",
       "9  [9750, 70852, 70852, 70852, 70852, 70852, 7085...          1   38594   \n",
       "\n",
       "   is_buy                                         next_state  len_next_states  \\\n",
       "0       0  [49432, 70852, 70852, 70852, 70852, 70852, 708...                1   \n",
       "1       0  [49432, 49432, 70852, 70852, 70852, 70852, 708...                2   \n",
       "2       0  [49432, 49432, 39563, 70852, 70852, 70852, 708...                3   \n",
       "3       0  [49432, 49432, 39563, 32776, 70852, 70852, 708...                4   \n",
       "4       0  [49432, 49432, 39563, 32776, 52161, 70852, 708...                5   \n",
       "5       0  [49432, 49432, 39563, 32776, 52161, 52161, 708...                6   \n",
       "6       0  [49432, 49432, 39563, 32776, 52161, 52161, 327...                7   \n",
       "7       0  [49432, 49432, 39563, 32776, 52161, 52161, 327...                8   \n",
       "8       1  [9750, 70852, 70852, 70852, 70852, 70852, 7085...                1   \n",
       "9       0  [9750, 38594, 70852, 70852, 70852, 70852, 7085...                2   \n",
       "\n",
       "   is_done  \n",
       "0    False  \n",
       "1    False  \n",
       "2    False  \n",
       "3    False  \n",
       "4    False  \n",
       "5    False  \n",
       "6    False  \n",
       "7     True  \n",
       "8    False  \n",
       "9    False  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "real_replay = pd.read_pickle(\"../data/RetailRocket/replay_buffer.df\")\n",
    "real_replay.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>action</th>\n",
       "      <th>next_state</th>\n",
       "      <th>action_type</th>\n",
       "      <th>is_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>742616</th>\n",
       "      <td>[70852, 70852, 70852, 70852, 70852, 70852, 708...</td>\n",
       "      <td>49432</td>\n",
       "      <td>[49432, 70852, 70852, 70852, 70852, 70852, 708...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735273</th>\n",
       "      <td>[49432, 70852, 70852, 70852, 70852, 70852, 708...</td>\n",
       "      <td>49432</td>\n",
       "      <td>[49432, 49432, 70852, 70852, 70852, 70852, 708...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737711</th>\n",
       "      <td>[49432, 49432, 70852, 70852, 70852, 70852, 708...</td>\n",
       "      <td>39563</td>\n",
       "      <td>[49432, 49432, 39563, 70852, 70852, 70852, 708...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726292</th>\n",
       "      <td>[49432, 49432, 39563, 70852, 70852, 70852, 708...</td>\n",
       "      <td>32776</td>\n",
       "      <td>[49432, 49432, 39563, 32776, 70852, 70852, 708...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>737615</th>\n",
       "      <td>[49432, 49432, 39563, 32776, 70852, 70852, 708...</td>\n",
       "      <td>52161</td>\n",
       "      <td>[49432, 49432, 39563, 32776, 52161, 70852, 708...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>735202</th>\n",
       "      <td>[49432, 49432, 39563, 32776, 52161, 70852, 708...</td>\n",
       "      <td>52161</td>\n",
       "      <td>[49432, 49432, 39563, 32776, 52161, 52161, 708...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>742485</th>\n",
       "      <td>[49432, 49432, 39563, 32776, 52161, 52161, 708...</td>\n",
       "      <td>32776</td>\n",
       "      <td>[49432, 49432, 39563, 32776, 52161, 52161, 327...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728288</th>\n",
       "      <td>[49432, 49432, 39563, 32776, 52161, 52161, 327...</td>\n",
       "      <td>49432</td>\n",
       "      <td>[49432, 49432, 39563, 32776, 52161, 52161, 327...</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133190</th>\n",
       "      <td>[70852, 70852, 70852, 70852, 70852, 70852, 708...</td>\n",
       "      <td>9750</td>\n",
       "      <td>[9750, 70852, 70852, 70852, 70852, 70852, 7085...</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135980</th>\n",
       "      <td>[9750, 70852, 70852, 70852, 70852, 70852, 7085...</td>\n",
       "      <td>38594</td>\n",
       "      <td>[9750, 38594, 70852, 70852, 70852, 70852, 7085...</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     state  action  \\\n",
       "742616   [70852, 70852, 70852, 70852, 70852, 70852, 708...   49432   \n",
       "735273   [49432, 70852, 70852, 70852, 70852, 70852, 708...   49432   \n",
       "737711   [49432, 49432, 70852, 70852, 70852, 70852, 708...   39563   \n",
       "726292   [49432, 49432, 39563, 70852, 70852, 70852, 708...   32776   \n",
       "737615   [49432, 49432, 39563, 32776, 70852, 70852, 708...   52161   \n",
       "735202   [49432, 49432, 39563, 32776, 52161, 70852, 708...   52161   \n",
       "742485   [49432, 49432, 39563, 32776, 52161, 52161, 708...   32776   \n",
       "728288   [49432, 49432, 39563, 32776, 52161, 52161, 327...   49432   \n",
       "1133190  [70852, 70852, 70852, 70852, 70852, 70852, 708...    9750   \n",
       "1135980  [9750, 70852, 70852, 70852, 70852, 70852, 7085...   38594   \n",
       "\n",
       "                                                next_state  action_type  \\\n",
       "742616   [49432, 70852, 70852, 70852, 70852, 70852, 708...            0   \n",
       "735273   [49432, 49432, 70852, 70852, 70852, 70852, 708...            0   \n",
       "737711   [49432, 49432, 39563, 70852, 70852, 70852, 708...            0   \n",
       "726292   [49432, 49432, 39563, 32776, 70852, 70852, 708...            0   \n",
       "737615   [49432, 49432, 39563, 32776, 52161, 70852, 708...            0   \n",
       "735202   [49432, 49432, 39563, 32776, 52161, 52161, 708...            0   \n",
       "742485   [49432, 49432, 39563, 32776, 52161, 52161, 327...            0   \n",
       "728288   [49432, 49432, 39563, 32776, 52161, 52161, 327...            0   \n",
       "1133190  [9750, 70852, 70852, 70852, 70852, 70852, 7085...            1   \n",
       "1135980  [9750, 38594, 70852, 70852, 70852, 70852, 7085...            0   \n",
       "\n",
       "         is_end  \n",
       "742616    False  \n",
       "735273    False  \n",
       "737711    False  \n",
       "726292    False  \n",
       "737615    False  \n",
       "735202    False  \n",
       "742485    False  \n",
       "728288     True  \n",
       "1133190   False  \n",
       "1135980   False  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_replay = pd.read_pickle(\"../data/RetailRocket/replay_buffer_replica.df\")\n",
    "my_replay.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compare states\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "my_state = np.array(my_replay.state.to_list())\n",
    "real_state = np.array(real_replay.state.to_list())\n",
    "\n",
    "(my_state==real_state).any(1).sum() == len(real_replay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_next = np.array(my_replay.next_state.to_list())\n",
    "real_next = np.array(real_replay.next_state.to_list())\n",
    "\n",
    "(my_next==real_next).any(1).sum() == len(real_replay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(my_replay.action.values==real_replay.action.values).sum()  == len(real_replay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.35"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "float(torch.tensor(1.35, dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.3885, -0.9343, -0.4991, -1.0867,  0.9624,  0.2492, -0.4845, -2.0929,\n",
      "          0.0983, -0.0935],\n",
      "        [ 0.2662, -0.5850, -0.3430, -0.6821, -0.9887, -1.7018, -1.2203,  1.3139,\n",
      "          1.0533,  0.1388],\n",
      "        [-0.2044, -2.2685, -0.9133, -0.4204,  0.2436, -0.0567,  0.3784,  1.6863,\n",
      "          0.2553, -0.5496],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000]], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0107,  0.0150, -0.0082,  0.0027, -0.0221, -0.0132, -0.0209,  0.0096,\n",
       "         -0.0099,  0.0122],\n",
       "        [-0.0023,  0.0134,  0.0199,  0.0137, -0.0050, -0.0028,  0.0123, -0.0110,\n",
       "         -0.0097,  0.0067],\n",
       "        [-0.0094, -0.0047,  0.0103, -0.0028, -0.0118, -0.0029, -0.0060,  0.0060,\n",
       "         -0.0142, -0.0022],\n",
       "        [ 0.0043, -0.0090, -0.0002,  0.0043, -0.0077, -0.0005, -0.0073,  0.0123,\n",
       "          0.0119, -0.0022]], requires_grad=True)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Embedding exps\n",
    "\n",
    "import torch.nn as nn \n",
    "\n",
    "embs = nn.Embedding(num_embeddings=4, embedding_dim=10, padding_idx=3)\n",
    "print(embs.weight)\n",
    "nn.init.normal_(embs.weight, 0, 0.01)\n",
    "embs.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  1.5810],\n",
      "        [ 1.3010,  1.2753, -0.2010, -0.1606, -0.4015],\n",
      "        [ 0.6957, -1.8061, -1.1589,  0.3255, -0.6315],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Still unaffected by gradient updates?\n",
    "torch.manual_seed(123)\n",
    "embs = nn.Embedding(num_embeddings=4, embedding_dim=5, padding_idx=3)\n",
    "print(embs.weight)\n",
    "result = embs(torch.tensor(0)) @ torch.tensor([10.0,10.0,0,8,0]) \n",
    "result.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10.,  0.,  8.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.],\n",
       "        [ 0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The gradient of the first lookup vector changed, this is the only one \n",
    "# that was present in the computaitons\n",
    "embs.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What happens now if we include the third row, will there \n",
    "# be a gradient?\n",
    "embs.weight.grad.zero_() \n",
    "result = embs(torch.tensor(3)) @ torch.tensor([10.0,10.0,0,8,0]) \n",
    "result.backward()\n",
    "embs.weight.grad\n",
    "\n",
    "# No gradient! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Should we make it trianable? Maybe ask Martin Kuhlmann, if we set\n",
    "# it to 0 that does not mean that the output is actually zero as a \n",
    "# hidden state, much more that influences that like bias, activation func,\n",
    "# hidden state init, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embs(torch.tensor([0,1,2])).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.2790, -0.7587,  0.5473,  0.4301, -0.7259],\n",
      "        [ 0.7346, -0.0845,  1.0757,  0.6367, -0.1943],\n",
      "        [-0.8614,  0.5338,  0.3940, -2.0565,  1.1062],\n",
      "        [ 0.4562,  0.0144, -0.6411,  2.3902, -1.4256]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Using None \n",
    "emb = nn.Embedding(num_embeddings=4, embedding_dim=5, padding_idx=None)\n",
    "print(emb.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0093, -1.8110, -0.2443,  0.1327, -0.1200],\n",
      "        [ 0.4884,  1.9431,  0.2169, -0.1464, -0.4490],\n",
      "        [-1.8926,  0.6000,  0.7692, -1.1323,  2.9590],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "emb = nn.Embedding(num_embeddings=4, embedding_dim=5, padding_idx=3)\n",
    "print(emb.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.8423, -2.4813,  0.1389,  2.2357,  0.4888],\n",
      "        [-0.0180,  0.8637,  0.2074,  0.5687, -0.0959],\n",
      "        [ 0.0046, -1.4321,  0.0373,  0.7058,  0.2657],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "bo = False\n",
    "emb = nn.Embedding(num_embeddings=4, embedding_dim=5, padding_idx=None if bo else 3)\n",
    "print(emb.weight)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why do they need to be of same length in batch?\n",
    "# Becaue the computational graph is created each forward pass\n",
    "# It must be the same for all in batch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2a5b7f050>"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seeds \n",
    "import torch\n",
    "torch.manual_seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.utils.rnn import pad_sequence, pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "sent_1 = torch.tensor([1,2,3,4])\n",
    "sent_2 = torch.tensor([5,6,7]) \n",
    "sent_3 = torch.tensor([8,9]) \n",
    "\n",
    "raw = [sent_1, sent_2, sent_3]  # batch_size = 3\n",
    "padded = pad_sequence(raw, batch_first=True )  # size: [25, 3, 300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4],\n",
       "        [5, 6, 7, 0],\n",
       "        [8, 9, 0, 0]])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(padded.shape)\n",
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 6])\n",
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603],\n",
      "        [-0.2196, -0.3792,  0.7671, -1.1925,  0.6984, -1.4097],\n",
      "        [ 0.1794,  1.8951,  0.4954,  0.2692, -0.0770, -1.0205],\n",
      "        [-0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010],\n",
      "        [ 0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255],\n",
      "        [-0.6315, -2.8400, -1.3250,  0.1784, -2.1338,  1.0524],\n",
      "        [-0.3885, -0.9343, -0.4991, -1.0867,  0.8805,  1.5542],\n",
      "        [ 0.6266, -0.1755,  1.3111, -0.2199,  0.2190,  0.2045],\n",
      "        [ 0.5146,  0.9938, -0.2587, -1.0826,  0.1036, -2.1996],\n",
      "        [-0.0885, -0.5612,  0.6716,  0.6933, -0.9487, -0.0765]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Add embedding\n",
    "embed = torch.nn.Embedding(num_embeddings=10, embedding_dim=6)\n",
    "print(embed.weight.shape)  # (Num_items, dim)\n",
    "\n",
    "print(embed.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603],\n",
      "        [-0.0885, -0.5612,  0.6716,  0.6933, -0.9487, -0.0765]],\n",
      "       grad_fn=<EmbeddingBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Let's ask for embedding of padding and 9\n",
    "print(embed(torch.tensor([0, 9])))  # Corresponging to numbers as index in table! All must be in! Not possible 10, 100 and only 2 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "# Embed padded:\n",
    "print(embed(padded).shape)  # (batch_size, length, dim)\n",
    "embed_pad = embed(padded) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([[-0.2196, -0.3792,  0.7671, -1.1925,  0.6984, -1.4097],\n",
      "        [-0.6315, -2.8400, -1.3250,  0.1784, -2.1338,  1.0524],\n",
      "        [ 0.5146,  0.9938, -0.2587, -1.0826,  0.1036, -2.1996],\n",
      "        [ 0.1794,  1.8951,  0.4954,  0.2692, -0.0770, -1.0205],\n",
      "        [-0.3885, -0.9343, -0.4991, -1.0867,  0.8805,  1.5542],\n",
      "        [-0.0885, -0.5612,  0.6716,  0.6933, -0.9487, -0.0765],\n",
      "        [-0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010],\n",
      "        [ 0.6266, -0.1755,  1.3111, -0.2199,  0.2190,  0.2045],\n",
      "        [ 0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255]],\n",
      "       grad_fn=<PackPaddedSequenceBackward0>), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=None, unsorted_indices=None)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 6])"
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lengths = torch.as_tensor([4,3,2], dtype=torch.int64)\n",
    "packed = pack_padded_sequence(embed_pad, lengths, batch_first=True)\n",
    "\n",
    "print(packed)\n",
    "packed.data.size() # Only keeps meaningful timesteps - 9 x embedding_size\n",
    "\n",
    "# col wise, position 1 of sq, how many have it? 3, all. How many have position 3? 2. Last step only 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn = torch.nn.RNN(input_size=6, hidden_size=2, batch_first=True)  # See here: Length is NOT even an argument\n",
    "padded_outp, padded_hn = rnn(embed_pad) # size: [25, 3, 2] / [1, 3, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All hidden states for all time steps: torch.Size([3, 4, 2])\n",
      "Last hidden state: torch.Size([3, 2]) \n",
      "\n",
      "tensor([[-0.0443,  0.8260],\n",
      "        [ 0.3320,  0.8101],\n",
      "        [ 0.2957,  0.9264]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(\"All hidden states for all time steps:\",  padded_outp.shape)  # (batch_size, num_steps, hidden_size)\n",
    "print(\"Last hidden state:\",  padded_hn[0,:,:].shape, \"\\n\")  # (batch_size, hidden_size)\n",
    "\n",
    "print(padded_hn[0,:,:])   # Here it is SliceBackward! We jsut slice it from whole hidden states, we can pass all at once since all same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.2196, -0.3792,  0.7671, -1.1925,  0.6984, -1.4097],\n",
       "        [-0.6315, -2.8400, -1.3250,  0.1784, -2.1338,  1.0524],\n",
       "        [ 0.5146,  0.9938, -0.2587, -1.0826,  0.1036, -2.1996],\n",
       "        [ 0.1794,  1.8951,  0.4954,  0.2692, -0.0770, -1.0205],\n",
       "        [-0.3885, -0.9343, -0.4991, -1.0867,  0.8805,  1.5542],\n",
       "        [-0.0885, -0.5612,  0.6716,  0.6933, -0.9487, -0.0765],\n",
       "        [-0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010],\n",
       "        [ 0.6266, -0.1755,  1.3111, -0.2199,  0.2190,  0.2045],\n",
       "        [ 0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255]],\n",
       "       grad_fn=<PackPaddedSequenceBackward0>), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 2])"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed_outp, packed_hn = rnn(packed) # 'PackedSequence' Obj / [1, 3, 2]\n",
    "# undo_packed_outp, _ = pad_packed_sequence(packed_outp)\n",
    "\n",
    "packed_outp.data.shape  # We only get hidden states for real data point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0443,  0.8260],\n",
       "         [ 0.5791,  0.4227],\n",
       "         [-0.0802,  0.6983]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Same size for final hidden state - no packed tensor anymore\n",
    "# We can see that only the first one has the same - which is the hidden state for \n",
    "# the undpadded seq! The others are different. \n",
    "# Also see here: The gradient func is StackBackward, they get stacked since not at similar time passing through because of diff shapes!!!\n",
    "packed_hn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.5791,  0.4227]],\n",
      "\n",
      "        [[-0.0802,  0.6983]]], grad_fn=<CatBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Let's see how to reproduce that:\n",
    "\n",
    "# Can we use RNN with dioffering lengths?\n",
    "examp_1 = embed(torch.tensor([[1,2], [3,4]]))\n",
    "_, h = rnn(examp_1) # YES. The RNN does not care about length. This is what packed is doing\n",
    "                    # Try to reproduce now:\n",
    "\n",
    "reproduce_row_1 = embed(torch.tensor([[5,6,7]]))\n",
    "reproduce_row_2 = embed(torch.tensor([[8,9]]))\n",
    "\n",
    "_, h_1 = rnn(reproduce_row_1)\n",
    "_, h_2 = rnn(reproduce_row_2)\n",
    "\n",
    "print(torch.cat([h_1,h_2]))\n",
    "\n",
    "# SAME result. So that means the padding indices are ignored and only the \"real\" data is passed.\n",
    "# Very important to note. That means we can improve performance AND eliminate the influence of \n",
    "# padding items entirely on the hidden states. WOW. So padding is just a way of passing it, but \n",
    "# will have nothing to do with gradient computaitons or outputs.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "`lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[237], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m embed_pad \u001b[39m=\u001b[39m embed(padded)\n\u001b[1;32m      5\u001b[0m lengths \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mas_tensor([\u001b[39m4\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m], dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mint64)\n\u001b[0;32m----> 6\u001b[0m packed \u001b[39m=\u001b[39m pack_padded_sequence(embed_pad, lengths, batch_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/RecommenderModels/lib/python3.9/site-packages/torch/nn/utils/rnn.py:262\u001b[0m, in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    258\u001b[0m     batch_dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m batch_first \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m    259\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mindex_select(batch_dim, sorted_indices)\n\u001b[1;32m    261\u001b[0m data, batch_sizes \u001b[39m=\u001b[39m \\\n\u001b[0;32m--> 262\u001b[0m     _VF\u001b[39m.\u001b[39;49m_pack_padded_sequence(\u001b[39minput\u001b[39;49m, lengths, batch_first)\n\u001b[1;32m    263\u001b[0m \u001b[39mreturn\u001b[39;00m _packed_sequence_init(data, batch_sizes, sorted_indices, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: `lengths` array must be sorted in decreasing order when `enforce_sorted` is True. You can pass `enforce_sorted=False` to pack_padded_sequence and/or pack_sequence to sidestep this requirement if you do not need ONNX exportability."
     ]
    }
   ],
   "source": [
    "# Now just explore sorting\n",
    "raw = [sent_1, sent_3, sent_2]\n",
    "padded = pad_sequence(raw, batch_first=True) \n",
    "embed_pad = embed(padded)\n",
    "lengths = torch.as_tensor([4,2,3], dtype=torch.int64)\n",
    "packed = pack_padded_sequence(embed_pad, lengths, batch_first=True)\n",
    "\n",
    "# Errror is raised if not sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw = [sent_1, sent_3, sent_2]\n",
    "padded = pad_sequence(raw, batch_first=True) \n",
    "embed_pad = embed(padded)\n",
    "lengths = torch.as_tensor([4,2,3], dtype=torch.int64)\n",
    "packed = pack_padded_sequence(embed_pad, lengths, batch_first=True, enforce_sorted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0443,  0.8260],\n",
       "         [-0.0802,  0.6983],\n",
       "         [ 0.5791,  0.4227]]], grad_fn=<IndexSelectBackward0>)"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, h = rnn(packed)\n",
    "\n",
    "h\n",
    "\n",
    "# Exaclty same output in right ordering (but of course just chenged 2 and 3 but not sorted by len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([104, 102, 103])"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Can we add to length\n",
    "lengths + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For why to use no_grad for whole next_state thing. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with setting pading_id\n",
    "\n",
    "Setting it to padding_id=0 - will it also be ignored in the hidden state computation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0443,  0.8260],\n",
       "         [ 0.3320,  0.8101],\n",
       "         [ 0.2957,  0.9264]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seeds \n",
    "import torch\n",
    "torch.manual_seed(123)\n",
    "\n",
    "raw = [sent_1, sent_2, sent_3]  # batch_size = 3\n",
    "padded = pad_sequence(raw, batch_first=True)  # size: [25, 3, 300]\n",
    "embed = torch.nn.Embedding(num_embeddings=10, embedding_dim=6)\n",
    "emb_pad = embed(padded)\n",
    "_, h = rnn(emb_pad)\n",
    "h\n",
    "\n",
    "# This is without the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [-0.2196, -0.3792,  0.7671, -1.1925,  0.6984, -1.4097],\n",
      "        [ 0.1794,  1.8951,  0.4954,  0.2692, -0.0770, -1.0205],\n",
      "        [-0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010],\n",
      "        [ 0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255],\n",
      "        [-0.6315, -2.8400, -1.3250,  0.1784, -2.1338,  1.0524],\n",
      "        [-0.3885, -0.9343, -0.4991, -1.0867,  0.8805,  1.5542],\n",
      "        [ 0.6266, -0.1755,  1.3111, -0.2199,  0.2190,  0.2045],\n",
      "        [ 0.5146,  0.9938, -0.2587, -1.0826,  0.1036, -2.1996],\n",
      "        [-0.0885, -0.5612,  0.6716,  0.6933, -0.9487, -0.0765]],\n",
      "       requires_grad=True)\n",
      "\n",
      "Embedding weights after changing manually:\n",
      "\n",
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603],\n",
      "        [-0.2196, -0.3792,  0.7671, -1.1925,  0.6984, -1.4097],\n",
      "        [ 0.1794,  1.8951,  0.4954,  0.2692, -0.0770, -1.0205],\n",
      "        [-0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010],\n",
      "        [ 0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255],\n",
      "        [-0.6315, -2.8400, -1.3250,  0.1784, -2.1338,  1.0524],\n",
      "        [-0.3885, -0.9343, -0.4991, -1.0867,  0.8805,  1.5542],\n",
      "        [ 0.6266, -0.1755,  1.3111, -0.2199,  0.2190,  0.2045],\n",
      "        [ 0.5146,  0.9938, -0.2587, -1.0826,  0.1036, -2.1996],\n",
      "        [-0.0885, -0.5612,  0.6716,  0.6933, -0.9487, -0.0765]],\n",
      "       requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0443,  0.8260],\n",
       "         [ 0.3320,  0.8101],\n",
       "         [ 0.2957,  0.9264]]], grad_fn=<StackBackward0>)"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seeds \n",
    "import torch\n",
    "torch.manual_seed(123)\n",
    "\n",
    "raw = [sent_1, sent_2, sent_3]  # batch_size = 3\n",
    "padded = pad_sequence(raw, batch_first=True)  # size: [25, 3, 300]\n",
    "embed = torch.nn.Embedding(num_embeddings=10, embedding_dim=6, padding_idx=0)\n",
    "\n",
    "print(embed.weight)  # The embedding of 0 is now set to 0s everywhere\n",
    "\n",
    "# To compare behaviour, set it to the same as initialized without the indexing\n",
    "with torch.no_grad():   \n",
    "    embed.weight[0] = torch.tensor([0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603])\n",
    "\n",
    "print(\"\\nEmbedding weights after changing manually:\\n\")\n",
    "print(embed.weight)  # The embedding of 0 is now set to 0s everywhere\n",
    "\n",
    "emb_pad = embed(padded)\n",
    "_, h = rnn(emb_pad)\n",
    "h\n",
    "\n",
    "# This is without the index\n",
    "h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603],\n",
      "        [-0.2196, -0.3792,  0.7671, -1.1925,  0.6984, -1.4097],\n",
      "        [ 0.1794,  1.8951,  0.4954,  0.2692, -0.0770, -1.0205],\n",
      "        [-0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010],\n",
      "        [ 0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255],\n",
      "        [-0.6315, -2.8400, -1.3250,  0.1784, -2.1338,  1.0524],\n",
      "        [-0.3885, -0.9343, -0.4991, -1.0867,  0.8805,  1.5542],\n",
      "        [ 0.6266, -0.1755,  1.3111, -0.2199,  0.2190,  0.2045],\n",
      "        [ 0.5146,  0.9938, -0.2587, -1.0826,  0.1036, -2.1996],\n",
      "        [-0.0885, -0.5612,  0.6716,  0.6933, -0.9487, -0.0765]],\n",
      "       requires_grad=True)\n",
      "PackedSequence(data=tensor([[-0.2196, -0.3792,  0.7671, -1.1925,  0.6984, -1.4097],\n",
      "        [ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603],\n",
      "        [ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603],\n",
      "        [ 0.1794,  1.8951,  0.4954,  0.2692, -0.0770, -1.0205],\n",
      "        [-0.6315, -2.8400, -1.3250,  0.1784, -2.1338,  1.0524],\n",
      "        [ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603],\n",
      "        [-0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010],\n",
      "        [-0.3885, -0.9343, -0.4991, -1.0867,  0.8805,  1.5542],\n",
      "        [ 0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255]],\n",
      "       grad_fn=<PackPaddedSequenceBackward0>), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=None, unsorted_indices=None)\n"
     ]
    }
   ],
   "source": [
    "# What happens if front padded?\n",
    "front_pad = torch.tensor([[1,2,3,4], [0,5,6,7], [0,0,8,9]])\n",
    "print(embed.weight)\n",
    "front_packed = pack_padded_sequence(embed(front_pad), lengths=[4,3,2], batch_first=True)\n",
    "print(front_packed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PackedSequence(data=tensor([[-0.2196, -0.3792,  0.7671, -1.1925,  0.6984, -1.4097],\n",
       "        [-0.6315, -2.8400, -1.3250,  0.1784, -2.1338,  1.0524],\n",
       "        [ 0.5146,  0.9938, -0.2587, -1.0826,  0.1036, -2.1996],\n",
       "        [ 0.1794,  1.8951,  0.4954,  0.2692, -0.0770, -1.0205],\n",
       "        [-0.3885, -0.9343, -0.4991, -1.0867,  0.8805,  1.5542],\n",
       "        [-0.0885, -0.5612,  0.6716,  0.6933, -0.9487, -0.0765],\n",
       "        [-0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010],\n",
       "        [ 0.6266, -0.1755,  1.3111, -0.2199,  0.2190,  0.2045],\n",
       "        [ 0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255]],\n",
       "       grad_fn=<PackPaddedSequenceBackward0>), batch_sizes=tensor([3, 3, 2, 1]), sorted_indices=None, unsorted_indices=None)"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "packed # Real packed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding token will be included and other info thrown away. It is CRUCIAL to have abck padding in this context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[325], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# What happens if entirely padded?\u001b[39;00m\n\u001b[1;32m      3\u001b[0m just_pad \u001b[39m=\u001b[39m embed(torch\u001b[39m.\u001b[39mtensor([[\u001b[39m1\u001b[39m,\u001b[39m2\u001b[39m,\u001b[39m3\u001b[39m], [\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m,\u001b[39m0\u001b[39m]]))\n\u001b[0;32m----> 4\u001b[0m pack_padded_sequence(just_pad, lengths\u001b[39m=\u001b[39;49m[\u001b[39m3\u001b[39;49m,\u001b[39m0\u001b[39;49m], batch_first\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/miniconda3/envs/RecommenderModels/lib/python3.9/site-packages/torch/nn/utils/rnn.py:262\u001b[0m, in \u001b[0;36mpack_padded_sequence\u001b[0;34m(input, lengths, batch_first, enforce_sorted)\u001b[0m\n\u001b[1;32m    258\u001b[0m     batch_dim \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m batch_first \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m\n\u001b[1;32m    259\u001b[0m     \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mindex_select(batch_dim, sorted_indices)\n\u001b[1;32m    261\u001b[0m data, batch_sizes \u001b[39m=\u001b[39m \\\n\u001b[0;32m--> 262\u001b[0m     _VF\u001b[39m.\u001b[39;49m_pack_padded_sequence(\u001b[39minput\u001b[39;49m, lengths, batch_first)\n\u001b[1;32m    263\u001b[0m \u001b[39mreturn\u001b[39;00m _packed_sequence_init(data, batch_sizes, sorted_indices, \u001b[39mNone\u001b[39;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Length of all samples has to be greater than 0, but found an element in 'lengths' that is <= 0"
     ]
    }
   ],
   "source": [
    "# What happens if entirely padded?\n",
    "# They use in their paper one padding token for the first \n",
    "# state since they artificially set the true_len to 1.\n",
    "\n",
    "# KEEP THAT IN MIND!\n",
    "\n",
    "just_pad = embed(torch.tensor([[1,2,3], [0,0,0]]))\n",
    "pack_padded_sequence(just_pad, lengths=[3,0], batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only save embedding layer\n",
    "from recommenders.SQN.gru_sqn import SQN_Network\n",
    "\n",
    "model_examp = SQN_Network(hidden_dim=64, item_num=100, state_size=10, embedding_dim=20, action_dim=250, gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0003, -0.0158, -0.0049,  ...,  0.0160, -0.0140,  0.0059],\n",
      "        [-0.0021,  0.0112, -0.0018,  ...,  0.0153, -0.0035, -0.0159],\n",
      "        [-0.0009,  0.0023, -0.0020,  ..., -0.0116,  0.0094, -0.0009],\n",
      "        ...,\n",
      "        [ 0.0044,  0.0015,  0.0126,  ..., -0.0024,  0.0067,  0.0147],\n",
      "        [-0.0149, -0.0058, -0.0068,  ...,  0.0012,  0.0017, -0.0196],\n",
      "        [ 0.0012,  0.0040,  0.0010,  ...,  0.0186,  0.0010, -0.0003]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(model_examp.embedding.weight)\n",
    "torch.save(model_examp.state_dict()[\"embedding.weight\"], f=\"weightsemb.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.0062,  0.0187, -0.0078,  ...,  0.0037, -0.0184,  0.0002],\n",
      "        [ 0.0030, -0.0094,  0.0180,  ...,  0.0087, -0.0047, -0.0006],\n",
      "        [ 0.0081, -0.0111,  0.0123,  ...,  0.0247, -0.0094,  0.0040],\n",
      "        ...,\n",
      "        [ 0.0055, -0.0126, -0.0064,  ..., -0.0025, -0.0005,  0.0065],\n",
      "        [-0.0175,  0.0009, -0.0009,  ...,  0.0120, -0.0039, -0.0192],\n",
      "        [ 0.0040,  0.0061,  0.0054,  ..., -0.0042,  0.0083, -0.0019]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0003, -0.0158, -0.0049,  ...,  0.0160, -0.0140,  0.0059],\n",
      "        [-0.0021,  0.0112, -0.0018,  ...,  0.0153, -0.0035, -0.0159],\n",
      "        [-0.0009,  0.0023, -0.0020,  ..., -0.0116,  0.0094, -0.0009],\n",
      "        ...,\n",
      "        [ 0.0044,  0.0015,  0.0126,  ..., -0.0024,  0.0067,  0.0147],\n",
      "        [-0.0149, -0.0058, -0.0068,  ...,  0.0012,  0.0017, -0.0196],\n",
      "        [ 0.0012,  0.0040,  0.0010,  ...,  0.0186,  0.0010, -0.0003]])\n"
     ]
    }
   ],
   "source": [
    "model_examp = SQN_Network(hidden_dim=64, item_num=100, state_size=10, embedding_dim=20, action_dim=250, gamma=0.5, )\n",
    "print(model_examp.embedding.weight)\n",
    "model_examp.embedding = model_examp.embedding.from_pretrained(torch.load(\"./weightsemb.pt\"), freeze=True)\n",
    "print(model_examp.embedding.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YES. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecommenderModels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d88d4b03a2ecce5ef9fa6e2b4fba24fc59644f272c7aa6cbff04d59cd6dbfc5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
