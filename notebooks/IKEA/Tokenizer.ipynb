{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer\n",
    "\n",
    "Create universal tokenizer for items/actions/countries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"../../data/IKEA/insp_feed_dict.json\", \"r\") as file:\n",
    "    if_dict = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9957"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(if_dict)\n",
    "\n",
    "# So there are 3600 imgs that were not shown at all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hallo', 'ich', 'bin', 'pat', '<unk>', '<pad>']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hallo': 0, 'ich': 1, 'bin': 2, 'pat': 3, '<unk>': 4, '<pad>': 5}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from recommenders.utils.tokenizer import Tokenizer\n",
    "tt = Tokenizer(vocabulary=[\"hallo\", \"ich\", \"bin\", \"pat\"], unknown=True)\n",
    "print(tt.itos_)\n",
    "tt.stoi_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hallo', 'ich', 'bin', 'pat', '<unk>', '<pad>', 'perter', 'parker', 'DDDD', 'HHHHHHHH']\n",
      "{'hallo': 0, 'ich': 1, 'bin': 2, 'pat': 3, '<unk>': 4, '<pad>': 5, 'perter': 5, 'parker': 6, 'DDDD': 7, 'HHHHHHHH': 8}\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Extend it\n",
    "tt.extend(new_vocabulary=[\"perter\", \"parker\"])\n",
    "tt.extend(new_vocabulary=[\"DDDD\", \"HHHHHHHH\"])\n",
    "\n",
    "print(tt.itos_)\n",
    "print(tt.stoi_)\n",
    "print(tt.unk_idx)\n",
    "print(tt.pad_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to file\n",
    "tt.save_to_file(file_path=\"./example_token.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hallo', 'ich', 'bin', 'pat', '<unk>', '<pad>', 'perter', 'parker', 'DDDD', 'HHHHHHHH']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hallo': 0,\n",
       " 'ich': 1,\n",
       " 'bin': 2,\n",
       " 'pat': 3,\n",
       " '<unk>': 4,\n",
       " '<pad>': 5,\n",
       " 'perter': 5,\n",
       " 'parker': 6,\n",
       " 'DDDD': 7,\n",
       " 'HHHHHHHH': 8}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Init form file \n",
    "tt_copy = Tokenizer.from_file(file_path=\"./example_token.json\")\n",
    "\n",
    "print(tt_copy.itos_)\n",
    "tt_copy.stoi_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Tokenizers\n",
    "\n",
    "### Combinded Image and item tokenizer \n",
    "\n",
    "This is a nice approach if we want to have the same indexes for both, the input and output layer. But it is only possible if the input dim larger than the output dim, then the output dim will be the first part togehther with \\<unk\\>, then we get \\<pad\\> and the extend it by the rest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load train dataset \n",
    "train = pd.read_csv(\"../../temp_data/temp_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "inspiration = train[train.action_type.isin([\"click_inspiration\", \"select_content\"])].item_id.unique()\n",
    "items = train[~train.action_type.isin([\"click_inspiration\", \"select_content\"])].item_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6304\n",
      "121106\n"
     ]
    }
   ],
   "source": [
    "print(len(inspiration))\n",
    "print(len(items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.utils.tokenizer import Tokenizer\n",
    "\n",
    "# Tokenizer for items and images\n",
    "# First add images from the training data and from the online dict \n",
    "# These will be the output layer.\n",
    "item_tok = Tokenizer(list(if_dict.keys()), unknown=True)\n",
    "item_tok.extend(items)\n",
    "\n",
    "item_tok.save_to_file(\"../../data/IKEA/tokenizers/tokenizer_items_images.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(item_tok.stoi_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_tok.stoi(\"<pad>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_item_tok = Tokenizer.from_file(\"../../data/IKEA/tokenizers/tokenizer_items_images.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_item_tok.stoi(\"<pad>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(loaded_item_tok.stoi_)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate tokenizers for input and output\n",
    "\n",
    "#### 1. Input\n",
    "\n",
    "The input dims will be all product and pictures inside the whole training set. \n",
    "\n",
    "- Take all inspirational images (otherwise there will be unknowns in the target)\n",
    "- Take only the products that are in the training set to mitigate bloating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load train dataset \n",
    "full = pd.read_csv(\"../../temp_data/temp_df.csv\")\n",
    "train = pd.read_csv(\"../../temp_data/temp_train.csv\")\n",
    "\n",
    "# Images in full data\n",
    "inspiration = full[full.action_type.isin([\"click_inspiration\", \"select_content\"])].item_id.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recommenders.utils.tokenizer import Tokenizer\n",
    "\n",
    "# Create tokenizer\n",
    "items_and_imgs = list(set().union(list(inspiration), train.item_id.unique()))\n",
    "\n",
    "input_tok = Tokenizer(items_and_imgs, unknown=True, padding=True)\n",
    "\n",
    "input_tok.save_to_file(\"../../data/IKEA/tokenizers/input_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127421\n",
      "127419\n",
      "127420\n",
      "127420\n",
      "127419\n"
     ]
    }
   ],
   "source": [
    "print(len(input_tok))\n",
    "print(input_tok.unk_idx)\n",
    "print(input_tok.pad_idx)\n",
    "print(input_tok.stoi(\"<pad>\"))\n",
    "print(input_tok.stoi(\"halloooo\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127421"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from recommenders.utils.tokenizer import Tokenizer\n",
    "loaded_item_tok = Tokenizer.from_file(\"../../data/IKEA/tokenizers/input_tokenizer.json\")\n",
    "len(loaded_item_tok.itos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76729"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_item_tok.stoi(\"19fd75f3-6716-4606-abbbe0498a52e1dd\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Output\n",
    "\n",
    "The output dims will be all pictures inside the whole dataset including the ones from the online json to make deployment easier later on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6313\n",
      "9957\n",
      "Total length: 10107\n"
     ]
    }
   ],
   "source": [
    "# Get union set of the two sources\n",
    "all_images = list(set().union(list(inspiration), if_dict.keys()))\n",
    "\n",
    "print(len(inspiration))\n",
    "print(len(if_dict))\n",
    "print(f\"Total length: {len(all_images)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create tokenizer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m output_tok \u001b[38;5;241m=\u001b[39m \u001b[43mTokenizer\u001b[49m(all_images, unknown\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      4\u001b[0m output_tok\u001b[38;5;241m.\u001b[39msave_to_file(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m../../data/IKEA/tokenizers/output_tokenizer.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Create tokenizer\n",
    "output_tok = Tokenizer(all_images, unknown=False, padding=True)\n",
    "\n",
    "output_tok.save_to_file(\"../../data/IKEA/tokenizers/output_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10107\n"
     ]
    }
   ],
   "source": [
    "print(len(output_tok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9299"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_item_tok = Tokenizer.from_file(\"../../data/IKEA/tokenizers/output_tokenizer.json\")\n",
    "loaded_item_tok.stoi(\"bd1ed584-fb37-4d0f-81ab8cc5aee4db0f\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Country tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "market_tok = Tokenizer(train.market.unique(), unknown=True, padding=True)\n",
    "market_tok.save_to_file(\"../../data/IKEA/tokenizers/market_tokenizer.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_tok.stoi(\"qa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "market_tok.stoi(\"hallo\")\n",
    "market_tok.stoi(\"morning\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RecommenderModels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
